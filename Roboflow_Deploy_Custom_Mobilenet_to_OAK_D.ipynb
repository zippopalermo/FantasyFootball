{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roboflow_Deploy_Custom_Mobilenet_to_OAK-D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJz_ToJtkufM"
      },
      "source": [
        "# Roboflow and DepthAI Tutorial: Train and Deploy a custom object detection model with depth! \n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)\n",
        "\n",
        "\n",
        "<img src=\"https://docs.luxonis.com/images/depthai_logo.png\" width=\"500\">\n",
        "\n",
        "We highly recommend working through this notebook with the corresponding blog post in hand. \n",
        "\n",
        "A Major shoutout to Luxonis, the creators of the OAK-D Device for originally putting this tutorial together. Here, we streamline the training process with data management, transformation, and exportation from Roboflow. \n",
        "\n",
        "At the end of this tutorial, you will have a custom trained object detection model to deploy to your OAK-D device!\n",
        "\n",
        "\n",
        "Insert GIF\n",
        "\n",
        "The steps we take to train and deploy our custom model are as follows \n",
        "\n",
        "\n",
        "* Install MobileNet Training Environment Dependencies\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TEgconcGvVK"
      },
      "source": [
        "# Install Training Environment Dependencies and Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH1x08R-yM-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3c9641-866b-4bdd-d261-072a9cfeb778"
      },
      "source": [
        "# %%capture\n",
        "#After this cell executes runtime will restart to finish the install, ignore and close the crash message, continue running cells starting with the one below\n",
        "!pip install numpy==1.17.5;\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.17.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/51/20098150b6108061cb7542af3de7bfcfe0182bca21613697153e49dc4adc/numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl (20.0MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0MB 1.3MB/s \n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.17.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.17.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z8kgcs0E7iV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39201ad3-835d-4cb4-f6b5-e5b739e1662b"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL"
      },
      "source": [
        "\n",
        "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
        "\n",
        "num_steps = 5000  # A step means using a single batch of data. larger batch, less steps required\n",
        "#60000 steps is required to train our example sign language dataset, less or more may be required based on your custom datasets needs\n",
        "\n",
        "#Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "#Batch size 24 is a setting that generally works well. can be changed higher or lower \n",
        "MODELS_CONFIG = {\n",
        "        'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 24\n",
        "    }\n",
        "}\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colab's GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "# Install Tensorflow Object Detection API\n",
        "\n",
        "Clone TF models which contains the Object Detection API; also install the required dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a502d1-c9d5-44b1-fb63-4c30fd187f56"
      },
      "source": [
        "# %%capture\n",
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "%cd /content/models/\n",
        "!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
        "!apt-get update && apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/models\n",
            "Note: checking out '58d19c67e1d30d905dd5c6e5092348658fed80af'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 58d19c67 Internal change\n",
            "Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,746 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [893 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,394 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,163 kB]\n",
            "Ign:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [602 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,964 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,396 kB]\n",
            "Fetched 11.4 MB in 3s (3,946 kB/s)\n",
            "Reading package lists... Done\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.5_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT0asaLNN1Vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855a0646-0a22-4e75-c272-96036d6bacc9"
      },
      "source": [
        "import os\n",
        "\n",
        "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 17.86 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcJhUwgCIKpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b448bf-c9a8-45de-aaff-f634158b78bf"
      },
      "source": [
        "%cd /content/tensorflow-object-detection-faster-rcnn/data\n",
        "\n",
        "!curl -L \"[YOUR-LINK-HERE]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   891  100   891    0     0   1405      0 --:--:-- --:--:-- --:--:--  1405\n",
            "100 22.2M  100 22.2M    0     0  12.8M      0  0:00:01  0:00:01 --:--:-- 24.8M\n",
            "Archive:  roboflow.zip\n",
            " extracting: test/Letters.tfrecord   \n",
            " extracting: train/Letters.tfrecord  \n",
            " extracting: valid/Letters.tfrecord  \n",
            " extracting: test/Letters_label_map.pbtxt  \n",
            " extracting: train/Letters_label_map.pbtxt  \n",
            " extracting: valid/Letters_label_map.pbtxt  \n",
            " extracting: README.roboflow.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4K8uaumM9zo"
      },
      "source": [
        "#RENAME Based on your annotation type - In this example our annotation type is \"letters\"\n",
        "#RENAME to the file path based on your download above ^^\n",
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/test/Letters.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/Letters.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/Letters_label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzMxk7UWyS6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2e7bc4-42c2-4e68-9d85-37a1370d8140"
      },
      "source": [
        "#double check that our class names came through\n",
        "#Rename based on your data above^^\n",
        "%cat '/content/tensorflow-object-detection-faster-rcnn/data/train/Letters_label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item {\n",
            "    name: \"A\",\n",
            "    id: 1,\n",
            "    display_name: \"A\"\n",
            "}\n",
            "item {\n",
            "    name: \"B\",\n",
            "    id: 2,\n",
            "    display_name: \"B\"\n",
            "}\n",
            "item {\n",
            "    name: \"C\",\n",
            "    id: 3,\n",
            "    display_name: \"C\"\n",
            "}\n",
            "item {\n",
            "    name: \"D\",\n",
            "    id: 4,\n",
            "    display_name: \"D\"\n",
            "}\n",
            "item {\n",
            "    name: \"E\",\n",
            "    id: 5,\n",
            "    display_name: \"E\"\n",
            "}\n",
            "item {\n",
            "    name: \"F\",\n",
            "    id: 6,\n",
            "    display_name: \"F\"\n",
            "}\n",
            "item {\n",
            "    name: \"G\",\n",
            "    id: 7,\n",
            "    display_name: \"G\"\n",
            "}\n",
            "item {\n",
            "    name: \"H\",\n",
            "    id: 8,\n",
            "    display_name: \"H\"\n",
            "}\n",
            "item {\n",
            "    name: \"I\",\n",
            "    id: 9,\n",
            "    display_name: \"I\"\n",
            "}\n",
            "item {\n",
            "    name: \"J\",\n",
            "    id: 10,\n",
            "    display_name: \"J\"\n",
            "}\n",
            "item {\n",
            "    name: \"K\",\n",
            "    id: 11,\n",
            "    display_name: \"K\"\n",
            "}\n",
            "item {\n",
            "    name: \"L\",\n",
            "    id: 12,\n",
            "    display_name: \"L\"\n",
            "}\n",
            "item {\n",
            "    name: \"M\",\n",
            "    id: 13,\n",
            "    display_name: \"M\"\n",
            "}\n",
            "item {\n",
            "    name: \"N\",\n",
            "    id: 14,\n",
            "    display_name: \"N\"\n",
            "}\n",
            "item {\n",
            "    name: \"O\",\n",
            "    id: 15,\n",
            "    display_name: \"O\"\n",
            "}\n",
            "item {\n",
            "    name: \"P\",\n",
            "    id: 16,\n",
            "    display_name: \"P\"\n",
            "}\n",
            "item {\n",
            "    name: \"Q\",\n",
            "    id: 17,\n",
            "    display_name: \"Q\"\n",
            "}\n",
            "item {\n",
            "    name: \"R\",\n",
            "    id: 18,\n",
            "    display_name: \"R\"\n",
            "}\n",
            "item {\n",
            "    name: \"S\",\n",
            "    id: 19,\n",
            "    display_name: \"S\"\n",
            "}\n",
            "item {\n",
            "    name: \"T\",\n",
            "    id: 20,\n",
            "    display_name: \"T\"\n",
            "}\n",
            "item {\n",
            "    name: \"U\",\n",
            "    id: 21,\n",
            "    display_name: \"U\"\n",
            "}\n",
            "item {\n",
            "    name: \"V\",\n",
            "    id: 22,\n",
            "    display_name: \"V\"\n",
            "}\n",
            "item {\n",
            "    name: \"W\",\n",
            "    id: 23,\n",
            "    display_name: \"W\"\n",
            "}\n",
            "item {\n",
            "    name: \"X\",\n",
            "    id: 24,\n",
            "    display_name: \"X\"\n",
            "}\n",
            "item {\n",
            "    name: \"Y\",\n",
            "    id: 25,\n",
            "    display_name: \"Y\"\n",
            "}\n",
            "item {\n",
            "    name: \"Z\",\n",
            "    id: 26,\n",
            "    display_name: \"Z\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MpYFYzNNumA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8277d0-93fc-43b3-a75e-21fca5c8fb25"
      },
      "source": [
        "!ls '/content/tensorflow-object-detection-faster-rcnn/data/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FYI.txt  README.roboflow.txt  test  train  valid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download the Mobilenet SSD v2 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1a541e-87dc-4d02-b220-d357507eab38"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 63 root   root  4.0K Mar 15 05:27 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f6a350d1-1ff7-41f0-fd37-00c79919de42"
      },
      "source": [
        "#TF pretrained model checkpoint\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ee55e1-a9e2-4e67-d807-bc307e4e361c"
      },
      "source": [
        "import re\n",
        "iou_threshold = 0.50\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    print(pipeline_fname)\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('iou_threshold: [0-9].[0-9]+',\n",
        "               'iou_threshold: {}'.format(iou_threshold), s)\n",
        "    \n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77701e94-94b7-4577-d7ef-17226e25caf2"
      },
      "source": [
        "# #Have a look at the config file with various settings\n",
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 26\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.5\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.5\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 24\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 5000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/Letters.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/Letters_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/test/Letters.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/Letters_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "# Train Custom Mobilenet Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c403a7e5-634c-453d-ffef-c82b1ec71c17"
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory for a fresh start.\n",
        "# !rm -rf {model_dir}\n",
        "# os.makedirs(model_dir, exist_ok=True)\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}\n",
        "\n",
        "#training will take a while (the TF OD library is not heavily optimized for speed on GPU), watch the mAP metrics rise, you can quit training early when you think your model has maxed out performance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0315 05:27:45.418380 140150642440064 model_lib.py:717] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0315 05:27:45.418617 140150642440064 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0315 05:27:45.418723 140150642440064 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0315 05:27:45.418805 140150642440064 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0315 05:27:45.418887 140150642440064 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0315 05:27:45.418983 140150642440064 config_util.py:552] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0315 05:27:45.419080 140150642440064 config_util.py:562] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0315 05:27:45.419356 140150642440064 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0315 05:27:45.419453 140150642440064 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f76f12b1b90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0315 05:27:45.419861 140150642440064 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f76f12b1b90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f76f19c3440>) includes params argument, but params are not passed to Estimator.\n",
            "W0315 05:27:45.420097 140150642440064 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f76f19c3440>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0315 05:27:45.420481 140150642440064 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0315 05:27:45.420651 140150642440064 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0315 05:27:45.420852 140150642440064 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0315 05:27:45.431553 140150642440064 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0315 05:27:45.459754 140150642440064 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0315 05:27:45.464159 140150642440064 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0315 05:27:45.480996 140150642440064 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f76f12a3e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0315 05:27:45.509247 140150642440064 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f76f12a3e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f76f19c38c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0315 05:27:45.693051 140150642440064 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f76f19c38c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0315 05:27:45.698652 140150642440064 deprecation.py:323] From /content/models/research/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0315 05:27:45.705446 140150642440064 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0315 05:27:45.792668 140150642440064 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0315 05:27:46.479063 140150642440064 deprecation.py:323] From /content/models/research/object_detection/inputs.py:260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0315 05:27:46.888763 140150642440064 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0315 05:27:47.351295 140150642440064 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:27:49.689635 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:27:49.717799 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:27:49.744849 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:27:49.771763 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:27:49.802875 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:27:49.830337 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "W0315 05:27:49.866722 140150642440064 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n",
            "W0315 05:27:49.866954 140150642440064 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0315 05:27:49.867086 140150642440064 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0315 05:27:49.867197 140150642440064 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0315 05:27:56.404168 140150642440064 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0315 05:28:02.027254 140150642440064 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0315 05:28:02.028494 140150642440064 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0315 05:28:05.457663 140150642440064 monitored_session.py:240] Graph was finalized.\n",
            "2021-03-15 05:28:05.458205: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2021-03-15 05:28:05.470068: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
            "2021-03-15 05:28:05.470356: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559143555340 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-15 05:28:05.470392: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-03-15 05:28:05.475255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-15 05:28:05.648843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:28:05.649593: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5591435556c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-15 05:28:05.649623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2021-03-15 05:28:05.651771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:28:05.652416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-15 05:28:05.667447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-15 05:28:05.845761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-15 05:28:05.947270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-15 05:28:05.965352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-15 05:28:06.161380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-15 05:28:06.178620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-15 05:28:06.534246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-15 05:28:06.534481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:28:06.535427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:28:06.536039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-15 05:28:06.539377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-15 05:28:06.541800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-15 05:28:06.541831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-15 05:28:06.541873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-15 05:28:06.542281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:28:06.542929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:28:06.543479: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-03-15 05:28:06.543522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0315 05:28:14.727911 140150642440064 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0315 05:28:15.142187 140150642440064 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0315 05:28:24.986397 140150642440064 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2021-03-15 05:28:35.677388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-15 05:28:38.416868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 19.374025, step = 0\n",
            "I0315 05:28:40.168561 140150642440064 basic_session_run_hooks.py:262] loss = 19.374025, step = 0\n",
            "INFO:tensorflow:global_step/sec: 3.00664\n",
            "I0315 05:29:13.427425 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.00664\n",
            "INFO:tensorflow:loss = 6.002081, step = 100 (33.260 sec)\n",
            "I0315 05:29:13.428640 140150642440064 basic_session_run_hooks.py:260] loss = 6.002081, step = 100 (33.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.60323\n",
            "I0315 05:29:41.180321 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.60323\n",
            "INFO:tensorflow:loss = 3.9366791, step = 200 (27.753 sec)\n",
            "I0315 05:29:41.181616 140150642440064 basic_session_run_hooks.py:260] loss = 3.9366791, step = 200 (27.753 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.58097\n",
            "I0315 05:30:09.105732 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.58097\n",
            "INFO:tensorflow:loss = 2.0978088, step = 300 (27.925 sec)\n",
            "I0315 05:30:09.107035 140150642440064 basic_session_run_hooks.py:260] loss = 2.0978088, step = 300 (27.925 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.60989\n",
            "I0315 05:30:36.807366 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.60989\n",
            "INFO:tensorflow:loss = 1.7953556, step = 400 (27.702 sec)\n",
            "I0315 05:30:36.808597 140150642440064 basic_session_run_hooks.py:260] loss = 1.7953556, step = 400 (27.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.63787\n",
            "I0315 05:31:04.295985 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.63787\n",
            "INFO:tensorflow:loss = 1.5844159, step = 500 (27.489 sec)\n",
            "I0315 05:31:04.297333 140150642440064 basic_session_run_hooks.py:260] loss = 1.5844159, step = 500 (27.489 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.61384\n",
            "I0315 05:31:31.967420 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.61384\n",
            "INFO:tensorflow:loss = 1.3691218, step = 600 (27.671 sec)\n",
            "I0315 05:31:31.968610 140150642440064 basic_session_run_hooks.py:260] loss = 1.3691218, step = 600 (27.671 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.63375\n",
            "I0315 05:31:59.487185 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.63375\n",
            "INFO:tensorflow:loss = 1.314717, step = 700 (27.520 sec)\n",
            "I0315 05:31:59.488380 140150642440064 basic_session_run_hooks.py:260] loss = 1.314717, step = 700 (27.520 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.60924\n",
            "I0315 05:32:27.193832 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.60924\n",
            "INFO:tensorflow:loss = 1.2398906, step = 800 (27.707 sec)\n",
            "I0315 05:32:27.195153 140150642440064 basic_session_run_hooks.py:260] loss = 1.2398906, step = 800 (27.707 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.60713\n",
            "I0315 05:32:54.916688 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.60713\n",
            "INFO:tensorflow:loss = 1.1957431, step = 900 (27.723 sec)\n",
            "I0315 05:32:54.917773 140150642440064 basic_session_run_hooks.py:260] loss = 1.1957431, step = 900 (27.723 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.66064\n",
            "I0315 05:33:22.234319 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.66064\n",
            "INFO:tensorflow:loss = 1.0295801, step = 1000 (27.318 sec)\n",
            "I0315 05:33:22.235675 140150642440064 basic_session_run_hooks.py:260] loss = 1.0295801, step = 1000 (27.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.62368\n",
            "I0315 05:33:49.830548 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.62368\n",
            "INFO:tensorflow:loss = 1.0514613, step = 1100 (27.596 sec)\n",
            "I0315 05:33:49.831669 140150642440064 basic_session_run_hooks.py:260] loss = 1.0514613, step = 1100 (27.596 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.53786\n",
            "I0315 05:34:18.096257 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.53786\n",
            "INFO:tensorflow:loss = 1.0389123, step = 1200 (28.266 sec)\n",
            "I0315 05:34:18.097681 140150642440064 basic_session_run_hooks.py:260] loss = 1.0389123, step = 1200 (28.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.57117\n",
            "I0315 05:34:46.098256 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.57117\n",
            "INFO:tensorflow:loss = 1.0176578, step = 1300 (28.002 sec)\n",
            "I0315 05:34:46.099324 140150642440064 basic_session_run_hooks.py:260] loss = 1.0176578, step = 1300 (28.002 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.58391\n",
            "I0315 05:35:14.000724 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.58391\n",
            "INFO:tensorflow:loss = 0.9398091, step = 1400 (27.902 sec)\n",
            "I0315 05:35:14.001800 140150642440064 basic_session_run_hooks.py:260] loss = 0.9398091, step = 1400 (27.902 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.54401\n",
            "I0315 05:35:42.217352 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.54401\n",
            "INFO:tensorflow:loss = 1.0842175, step = 1500 (28.217 sec)\n",
            "I0315 05:35:42.218301 140150642440064 basic_session_run_hooks.py:260] loss = 1.0842175, step = 1500 (28.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.55805\n",
            "I0315 05:36:10.322627 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.55805\n",
            "INFO:tensorflow:loss = 1.1006696, step = 1600 (28.106 sec)\n",
            "I0315 05:36:10.323887 140150642440064 basic_session_run_hooks.py:260] loss = 1.1006696, step = 1600 (28.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.56583\n",
            "I0315 05:36:38.366566 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.56583\n",
            "INFO:tensorflow:loss = 1.1570243, step = 1700 (28.044 sec)\n",
            "I0315 05:36:38.367640 140150642440064 basic_session_run_hooks.py:260] loss = 1.1570243, step = 1700 (28.044 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.59699\n",
            "I0315 05:37:06.167574 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.59699\n",
            "INFO:tensorflow:loss = 1.0464565, step = 1800 (27.801 sec)\n",
            "I0315 05:37:06.168837 140150642440064 basic_session_run_hooks.py:260] loss = 1.0464565, step = 1800 (27.801 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.58061\n",
            "I0315 05:37:34.095791 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.58061\n",
            "INFO:tensorflow:loss = 1.0923744, step = 1900 (27.928 sec)\n",
            "I0315 05:37:34.096861 140150642440064 basic_session_run_hooks.py:260] loss = 1.0923744, step = 1900 (27.928 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.58672\n",
            "I0315 05:38:01.976430 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.58672\n",
            "INFO:tensorflow:loss = 0.9062005, step = 2000 (27.881 sec)\n",
            "I0315 05:38:01.977701 140150642440064 basic_session_run_hooks.py:260] loss = 0.9062005, step = 2000 (27.881 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2093 into training/model.ckpt.\n",
            "I0315 05:38:27.568572 140150642440064 basic_session_run_hooks.py:606] Saving checkpoints for 2093 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f76dc579250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0315 05:38:29.190473 140150642440064 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f76dc579250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f76e900ccb0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0315 05:38:29.372391 140150642440064 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f76e900ccb0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0315 05:38:29.871724 140150642440064 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:38:32.103453 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:38:32.133116 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:38:32.162709 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:38:32.192506 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:38:32.221337 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:38:32.250122 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0315 05:38:33.651059 140150642440064 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0315 05:38:33.826789 140150642440064 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0315 05:38:34.327736 140150642440064 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-03-15T05:38:34Z\n",
            "I0315 05:38:34.344007 140150642440064 evaluation.py:255] Starting evaluation at 2021-03-15T05:38:34Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0315 05:38:34.720757 140150642440064 monitored_session.py:240] Graph was finalized.\n",
            "2021-03-15 05:38:34.721925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:38:34.722444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-15 05:38:34.722539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-15 05:38:34.722569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-15 05:38:34.722592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-15 05:38:34.722618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-15 05:38:34.722642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-15 05:38:34.722662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-15 05:38:34.722683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-15 05:38:34.722764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:38:34.723296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:38:34.723732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-15 05:38:34.723780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-15 05:38:34.723793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-15 05:38:34.723802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-15 05:38:34.723902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:38:34.724377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:38:34.724821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2093\n",
            "I0315 05:38:34.725931 140150642440064 saver.py:1284] Restoring parameters from training/model.ckpt-2093\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0315 05:38:35.670912 140150642440064 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0315 05:38:35.817039 140150642440064 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 72 images.\n",
            "I0315 05:38:40.737462 140148310017792 coco_evaluation.py:237] Performing evaluation on 72 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0315 05:38:40.738693 140148310017792 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0315 05:38:40.742257 140148310017792 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.25s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.136\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
            "INFO:tensorflow:Finished evaluation at 2021-03-15-05:38:41\n",
            "I0315 05:38:41.636349 140150642440064 evaluation.py:275] Finished evaluation at 2021-03-15-05:38:41\n",
            "INFO:tensorflow:Saving dict for global step 2093: DetectionBoxes_Precision/mAP = 0.13267472, DetectionBoxes_Precision/mAP (large) = 0.13284294, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.24281265, DetectionBoxes_Precision/mAP@.75IOU = 0.13636377, DetectionBoxes_Recall/AR@1 = 0.44027779, DetectionBoxes_Recall/AR@10 = 0.5192361, DetectionBoxes_Recall/AR@100 = 0.5223611, DetectionBoxes_Recall/AR@100 (large) = 0.5223611, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 1.5814482, Loss/localization_loss = 0.3885486, Loss/regularization_loss = 0.2545784, Loss/total_loss = 2.224575, global_step = 2093, learning_rate = 0.004, loss = 2.224575\n",
            "I0315 05:38:41.636646 140150642440064 estimator.py:2049] Saving dict for global step 2093: DetectionBoxes_Precision/mAP = 0.13267472, DetectionBoxes_Precision/mAP (large) = 0.13284294, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.24281265, DetectionBoxes_Precision/mAP@.75IOU = 0.13636377, DetectionBoxes_Recall/AR@1 = 0.44027779, DetectionBoxes_Recall/AR@10 = 0.5192361, DetectionBoxes_Recall/AR@100 = 0.5223611, DetectionBoxes_Recall/AR@100 (large) = 0.5223611, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 1.5814482, Loss/localization_loss = 0.3885486, Loss/regularization_loss = 0.2545784, Loss/total_loss = 2.224575, global_step = 2093, learning_rate = 0.004, loss = 2.224575\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2093: training/model.ckpt-2093\n",
            "I0315 05:38:42.504749 140150642440064 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2093: training/model.ckpt-2093\n",
            "INFO:tensorflow:global_step/sec: 2.3375\n",
            "I0315 05:38:44.757191 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 2.3375\n",
            "INFO:tensorflow:loss = 0.94799423, step = 2100 (42.781 sec)\n",
            "I0315 05:38:44.758293 140150642440064 basic_session_run_hooks.py:260] loss = 0.94799423, step = 2100 (42.781 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.57492\n",
            "I0315 05:39:12.729859 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.57492\n",
            "INFO:tensorflow:loss = 1.0400134, step = 2200 (27.973 sec)\n",
            "I0315 05:39:12.731254 140150642440064 basic_session_run_hooks.py:260] loss = 1.0400134, step = 2200 (27.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.58325\n",
            "I0315 05:39:40.637473 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.58325\n",
            "INFO:tensorflow:loss = 0.9204788, step = 2300 (27.907 sec)\n",
            "I0315 05:39:40.638712 140150642440064 basic_session_run_hooks.py:260] loss = 0.9204788, step = 2300 (27.907 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.59888\n",
            "I0315 05:40:08.423868 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.59888\n",
            "INFO:tensorflow:loss = 0.9966588, step = 2400 (27.786 sec)\n",
            "I0315 05:40:08.425078 140150642440064 basic_session_run_hooks.py:260] loss = 0.9966588, step = 2400 (27.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.59818\n",
            "I0315 05:40:36.215713 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.59818\n",
            "INFO:tensorflow:loss = 0.9280684, step = 2500 (27.792 sec)\n",
            "I0315 05:40:36.216754 140150642440064 basic_session_run_hooks.py:260] loss = 0.9280684, step = 2500 (27.792 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.59278\n",
            "I0315 05:41:04.049288 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.59278\n",
            "INFO:tensorflow:loss = 0.8498721, step = 2600 (27.834 sec)\n",
            "I0315 05:41:04.050633 140150642440064 basic_session_run_hooks.py:260] loss = 0.8498721, step = 2600 (27.834 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.61575\n",
            "I0315 05:41:31.706089 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.61575\n",
            "INFO:tensorflow:loss = 0.8735045, step = 2700 (27.657 sec)\n",
            "I0315 05:41:31.707314 140150642440064 basic_session_run_hooks.py:260] loss = 0.8735045, step = 2700 (27.657 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.62674\n",
            "I0315 05:41:59.279149 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.62674\n",
            "INFO:tensorflow:loss = 0.9089732, step = 2800 (27.573 sec)\n",
            "I0315 05:41:59.280248 140150642440064 basic_session_run_hooks.py:260] loss = 0.9089732, step = 2800 (27.573 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.60438\n",
            "I0315 05:42:27.023127 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.60438\n",
            "INFO:tensorflow:loss = 0.88035816, step = 2900 (27.744 sec)\n",
            "I0315 05:42:27.024353 140150642440064 basic_session_run_hooks.py:260] loss = 0.88035816, step = 2900 (27.744 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.63683\n",
            "I0315 05:42:54.519570 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.63683\n",
            "INFO:tensorflow:loss = 0.96209306, step = 3000 (27.496 sec)\n",
            "I0315 05:42:54.520796 140150642440064 basic_session_run_hooks.py:260] loss = 0.96209306, step = 3000 (27.496 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.55205\n",
            "I0315 05:43:22.672325 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.55205\n",
            "INFO:tensorflow:loss = 1.1242673, step = 3100 (28.153 sec)\n",
            "I0315 05:43:22.673296 140150642440064 basic_session_run_hooks.py:260] loss = 1.1242673, step = 3100 (28.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6176\n",
            "I0315 05:43:50.315023 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.6176\n",
            "INFO:tensorflow:loss = 0.84035957, step = 3200 (27.643 sec)\n",
            "I0315 05:43:50.316239 140150642440064 basic_session_run_hooks.py:260] loss = 0.84035957, step = 3200 (27.643 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.61626\n",
            "I0315 05:44:17.967852 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.61626\n",
            "INFO:tensorflow:loss = 0.8689146, step = 3300 (27.653 sec)\n",
            "I0315 05:44:17.968889 140150642440064 basic_session_run_hooks.py:260] loss = 0.8689146, step = 3300 (27.653 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.59966\n",
            "I0315 05:44:45.748247 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.59966\n",
            "INFO:tensorflow:loss = 0.9229649, step = 3400 (27.780 sec)\n",
            "I0315 05:44:45.749362 140150642440064 basic_session_run_hooks.py:260] loss = 0.9229649, step = 3400 (27.780 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.60121\n",
            "I0315 05:45:13.516717 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.60121\n",
            "INFO:tensorflow:loss = 0.8318072, step = 3500 (27.768 sec)\n",
            "I0315 05:45:13.517811 140150642440064 basic_session_run_hooks.py:260] loss = 0.8318072, step = 3500 (27.768 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.61034\n",
            "I0315 05:45:41.214953 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.61034\n",
            "INFO:tensorflow:loss = 0.98561275, step = 3600 (27.698 sec)\n",
            "I0315 05:45:41.216116 140150642440064 basic_session_run_hooks.py:260] loss = 0.98561275, step = 3600 (27.698 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.63163\n",
            "I0315 05:46:08.750813 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.63163\n",
            "INFO:tensorflow:loss = 0.8322799, step = 3700 (27.536 sec)\n",
            "I0315 05:46:08.751953 140150642440064 basic_session_run_hooks.py:260] loss = 0.8322799, step = 3700 (27.536 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.59864\n",
            "I0315 05:46:36.539091 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.59864\n",
            "INFO:tensorflow:loss = 0.81606305, step = 3800 (27.788 sec)\n",
            "I0315 05:46:36.540106 140150642440064 basic_session_run_hooks.py:260] loss = 0.81606305, step = 3800 (27.788 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.61896\n",
            "I0315 05:47:04.171316 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.61896\n",
            "INFO:tensorflow:loss = 0.88388455, step = 3900 (27.632 sec)\n",
            "I0315 05:47:04.172575 140150642440064 basic_session_run_hooks.py:260] loss = 0.88388455, step = 3900 (27.632 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.63244\n",
            "I0315 05:47:31.701056 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.63244\n",
            "INFO:tensorflow:loss = 0.77386594, step = 4000 (27.530 sec)\n",
            "I0315 05:47:31.702184 140150642440064 basic_session_run_hooks.py:260] loss = 0.77386594, step = 4000 (27.530 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.57401\n",
            "I0315 05:47:59.680765 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.57401\n",
            "INFO:tensorflow:loss = 0.7886143, step = 4100 (27.980 sec)\n",
            "I0315 05:47:59.681857 140150642440064 basic_session_run_hooks.py:260] loss = 0.7886143, step = 4100 (27.980 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4201 into training/model.ckpt.\n",
            "I0315 05:48:27.655304 140150642440064 basic_session_run_hooks.py:606] Saving checkpoints for 4201 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0315 05:48:29.082155 140150642440064 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 3.40102\n",
            "I0315 05:48:29.083642 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.40102\n",
            "INFO:tensorflow:loss = 0.8587705, step = 4200 (29.403 sec)\n",
            "I0315 05:48:29.084677 140150642440064 basic_session_run_hooks.py:260] loss = 0.8587705, step = 4200 (29.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.60349\n",
            "I0315 05:48:56.834565 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.60349\n",
            "INFO:tensorflow:loss = 0.7907926, step = 4300 (27.751 sec)\n",
            "I0315 05:48:56.835708 140150642440064 basic_session_run_hooks.py:260] loss = 0.7907926, step = 4300 (27.751 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.60291\n",
            "I0315 05:49:24.589936 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.60291\n",
            "INFO:tensorflow:loss = 0.88471854, step = 4400 (27.755 sec)\n",
            "I0315 05:49:24.591170 140150642440064 basic_session_run_hooks.py:260] loss = 0.88471854, step = 4400 (27.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.63557\n",
            "I0315 05:49:52.095884 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.63557\n",
            "INFO:tensorflow:loss = 0.781661, step = 4500 (27.506 sec)\n",
            "I0315 05:49:52.097103 140150642440064 basic_session_run_hooks.py:260] loss = 0.781661, step = 4500 (27.506 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.59151\n",
            "I0315 05:50:19.939344 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.59151\n",
            "INFO:tensorflow:loss = 0.8733305, step = 4600 (27.844 sec)\n",
            "I0315 05:50:19.940647 140150642440064 basic_session_run_hooks.py:260] loss = 0.8733305, step = 4600 (27.844 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6252\n",
            "I0315 05:50:47.524052 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.6252\n",
            "INFO:tensorflow:loss = 1.1065898, step = 4700 (27.584 sec)\n",
            "I0315 05:50:47.525127 140150642440064 basic_session_run_hooks.py:260] loss = 1.1065898, step = 4700 (27.584 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.6053\n",
            "I0315 05:51:15.260958 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.6053\n",
            "INFO:tensorflow:loss = 0.8085971, step = 4800 (27.737 sec)\n",
            "I0315 05:51:15.262082 140150642440064 basic_session_run_hooks.py:260] loss = 0.8085971, step = 4800 (27.737 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.61232\n",
            "I0315 05:51:42.944041 140150642440064 basic_session_run_hooks.py:692] global_step/sec: 3.61232\n",
            "INFO:tensorflow:loss = 0.86275685, step = 4900 (27.683 sec)\n",
            "I0315 05:51:42.945140 140150642440064 basic_session_run_hooks.py:260] loss = 0.86275685, step = 4900 (27.683 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into training/model.ckpt.\n",
            "I0315 05:52:10.321790 140150642440064 basic_session_run_hooks.py:606] Saving checkpoints for 5000 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f76527e4e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0315 05:52:11.830570 140150642440064 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f76527e4e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f76523e9170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0315 05:52:11.993415 140150642440064 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f76523e9170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0315 05:52:12.456622 140150642440064 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:14.763030 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:14.795378 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:14.822849 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:14.850832 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:14.878051 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:14.905424 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0315 05:52:16.942667 140150642440064 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-03-15T05:52:16Z\n",
            "I0315 05:52:16.957528 140150642440064 evaluation.py:255] Starting evaluation at 2021-03-15T05:52:16Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0315 05:52:17.331694 140150642440064 monitored_session.py:240] Graph was finalized.\n",
            "2021-03-15 05:52:17.332517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:52:17.333075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-15 05:52:17.333187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-15 05:52:17.333213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-15 05:52:17.333236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-15 05:52:17.333257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-15 05:52:17.333277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-15 05:52:17.333296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-15 05:52:17.333318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-15 05:52:17.333406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:52:17.333917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:52:17.334343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-15 05:52:17.334396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-15 05:52:17.334409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-15 05:52:17.334418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-15 05:52:17.334519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:52:17.335014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:52:17.335448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5000\n",
            "I0315 05:52:17.336668 140150642440064 saver.py:1284] Restoring parameters from training/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0315 05:52:18.296350 140150642440064 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0315 05:52:18.454506 140150642440064 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 72 images.\n",
            "I0315 05:52:23.320367 140148310017792 coco_evaluation.py:237] Performing evaluation on 72 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0315 05:52:23.320846 140148310017792 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0315 05:52:23.326674 140148310017792 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.52s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.27s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.362\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.712\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.722\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.722\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.722\n",
            "INFO:tensorflow:Finished evaluation at 2021-03-15-05:52:24\n",
            "I0315 05:52:24.224047 140150642440064 evaluation.py:275] Finished evaluation at 2021-03-15-05:52:24\n",
            "INFO:tensorflow:Saving dict for global step 5000: DetectionBoxes_Precision/mAP = 0.29183403, DetectionBoxes_Precision/mAP (large) = 0.29184657, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.42810926, DetectionBoxes_Precision/mAP@.75IOU = 0.36223808, DetectionBoxes_Recall/AR@1 = 0.711875, DetectionBoxes_Recall/AR@10 = 0.72229165, DetectionBoxes_Recall/AR@100 = 0.72229165, DetectionBoxes_Recall/AR@100 (large) = 0.72229165, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.63388944, Loss/localization_loss = 0.07272454, Loss/regularization_loss = 0.25346485, Loss/total_loss = 0.96007895, global_step = 5000, learning_rate = 0.004, loss = 0.96007895\n",
            "I0315 05:52:24.224323 140150642440064 estimator.py:2049] Saving dict for global step 5000: DetectionBoxes_Precision/mAP = 0.29183403, DetectionBoxes_Precision/mAP (large) = 0.29184657, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.42810926, DetectionBoxes_Precision/mAP@.75IOU = 0.36223808, DetectionBoxes_Recall/AR@1 = 0.711875, DetectionBoxes_Recall/AR@10 = 0.72229165, DetectionBoxes_Recall/AR@100 = 0.72229165, DetectionBoxes_Recall/AR@100 (large) = 0.72229165, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.63388944, Loss/localization_loss = 0.07272454, Loss/regularization_loss = 0.25346485, Loss/total_loss = 0.96007895, global_step = 5000, learning_rate = 0.004, loss = 0.96007895\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: training/model.ckpt-5000\n",
            "I0315 05:52:24.226451 140150642440064 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5000: training/model.ckpt-5000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0315 05:52:24.227172 140150642440064 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0315 05:52:24.461589 140150642440064 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:26.425224 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:26.454493 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:26.482319 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:26.509760 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:26.537153 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0315 05:52:26.564606 140150642440064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0315 05:52:28.337801 140150642440064 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0315 05:52:28.338118 140150642440064 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0315 05:52:28.338740 140150642440064 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0315 05:52:28.338857 140150642440064 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0315 05:52:28.338956 140150642440064 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0315 05:52:28.339030 140150642440064 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0315 05:52:28.339097 140150642440064 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2021-03-15 05:52:28.340314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:52:28.340841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-15 05:52:28.340950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-15 05:52:28.340977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-15 05:52:28.340999: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-15 05:52:28.341018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-15 05:52:28.341039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-15 05:52:28.341057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-15 05:52:28.341077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-15 05:52:28.341167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:52:28.341662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:52:28.342125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-15 05:52:28.342173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-15 05:52:28.342188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-15 05:52:28.342198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-15 05:52:28.342303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:52:28.342842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-15 05:52:28.343290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5000\n",
            "I0315 05:52:28.345906 140150642440064 saver.py:1284] Restoring parameters from training/model.ckpt-5000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0315 05:52:28.858502 140150642440064 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0315 05:52:28.858723 140150642440064 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1615787544'/saved_model.pb\n",
            "I0315 05:52:29.744315 140150642440064 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1615787544'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.8077575.\n",
            "I0315 05:52:30.185256 140150642440064 estimator.py:371] Loss for final step: 0.8077575.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c66569-67a8-4921-ccbd-b995b8a93b81"
      },
      "source": [
        "#model dir check for the trained model\n",
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1615786083.890c419d93e9\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-0.data-00000-of-00001\n",
            "model.ckpt-0.index\n",
            "model.ckpt-0.meta\n",
            "model.ckpt-2093.data-00000-of-00001\n",
            "model.ckpt-2093.index\n",
            "model.ckpt-2093.meta\n",
            "model.ckpt-4201.data-00000-of-00001\n",
            "model.ckpt-4201.index\n",
            "model.ckpt-4201.meta\n",
            "model.ckpt-5000.data-00000-of-00001\n",
            "model.ckpt-5000.index\n",
            "model.ckpt-5000.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Export a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZJ_AF5MD3hZ"
      },
      "source": [
        "#clean output_directory if necessary to start fresh:\n",
        "\n",
        "# !rm -rf /content/object_detection_demo/fine_tuned_model/ \n",
        "# os.makedirs('/content/object_detection_demo_flow/fine_tuned_model/', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq"
      },
      "source": [
        "%%capture\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "# output_directory = '/content/gdrive/My\\ Drive/data/'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD"
      },
      "source": [
        "#export directory check\n",
        "# !ls {output_directory}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr"
      },
      "source": [
        "import os\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"saved_model/saved_model.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)\n",
        "# !ls -alh {pb_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZHHqjjfMurV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ac2dce58-b8e8-4adc-e038-bd557cff6fda"
      },
      "source": [
        "#download frozen graph for posterity, you can keep this so you don't have to start over on training\n",
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3e62cd69-e5ae-44fd-baa7-ae4d2c9079f3\", \"saved_model.pb\", 21358853)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz1gX19GlVW7"
      },
      "source": [
        "## Running Inference: Checking what the trained model can detect\n",
        "Test with images in repository `tensorflow-object-detection-faster-rcnn/data/images/final test` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iydNnHsvz5II"
      },
      "source": [
        "#You will need to import test images into the test folder specified below - In Roboflow you can export raw images in YOLO Darknet format\n",
        "\n",
        "test_folder = '/content/tensorflow-object-detection-faster-rcnn'\n",
        "sample_img = 'https://storage.googleapis.com/roboflow-platform-transforms/D7CAGZafFYZMvKbKibZGc42BUAx2/56694b0cb356d57b9da4914993042958/transformed.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f8afc2-5f8b-49e9-ad65-6693b882b2bb"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR = test_folder + \"/data/test/\"\n",
        "\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(sample_img, \n",
        "                           PATH_TO_TEST_IMAGES_DIR + \"language.jpg\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/tensorflow-object-detection-faster-rcnn/data/test/language.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "64b09719-cc15-402b-e139-4e9613a33039"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    PATH_TO_CKPT = '/content/models/research/fine_tuned_model/frozen_inference_graph.pb'\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    print(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n",
            "/content/tensorflow-object-detection-faster-rcnn/data/test/language.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PlfZAR1OCK2"
      },
      "source": [
        "# Convert TF model to OpenVINO 20.01 Intermediate Representation (IR)\n",
        " This can be used to run inference on OpenVINO.\n",
        "# In order to run the model on DepthAI modules, we then compile the IR obtained above to a .blob (via a server we set up just for that) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qucQJwsWhL3"
      },
      "source": [
        "## First, we install Open Vino 20.01\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BxCxkQ6NkcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5686de-6660-4595-d062-827ce0c7e71a"
      },
      "source": [
        "%cd ../.."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5py5tfxS6VaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff5d6a4-c4f4-49d3-c001-385033003f6d"
      },
      "source": [
        "%%time\n",
        "# %%capture\n",
        "## install tools. Open Vino takes some time to download: 10-15 min sometimes.\n",
        "!sudo apt-get install -y pciutils cpio\n",
        "!sudo apt autoremove\n",
        "## downnload installation files\n",
        "!wget http://registrationcenter-download.intel.com/akdlm/irc_nas/16345/l_openvino_toolkit_p_2020.1.023.tgz\n",
        "path = \"l_openvino_toolkit_p_2020.1.023.tgz\"\n",
        "# path = \"/content/software/Intel OpenVINO 2019 R3.1/l_openvino_toolkit_p_2019.3.376.tgz\"\n",
        "## install openvino\n",
        "!tar xf \"{path}\"\n",
        "# !tar xf \"{path}\" && \\\n",
        "#     cd l_openvino_toolkit_p* && \\\n",
        "#     ./install_openvino_dependencies.sh && \\\n",
        "#     sed -i 's/decline/accept/g' silent.cfg && \\\n",
        "#     ./install.sh\n",
        "# ## install dependencies\n",
        "# !/opt/intel/openvino/install_dependencies/install_openvino_dependencies.sh\n",
        "# ## install prerequisites\n",
        "# !/opt/intel/openvino/deployment_tools/model_optimizer/install_prerequisites/install_prerequisites.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpci3\n",
            "Suggested packages:\n",
            "  libarchive1\n",
            "The following NEW packages will be installed:\n",
            "  cpio libpci3 pciutils\n",
            "0 upgraded, 3 newly installed, 0 to remove and 48 not upgraded.\n",
            "Need to get 368 kB of archives.\n",
            "After this operation, 1,786 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 cpio amd64 2.12+dfsg-6ubuntu0.18.04.1 [86.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpci3 amd64 1:3.5.2-1ubuntu1.1 [24.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 pciutils amd64 1:3.5.2-1ubuntu1.1 [257 kB]\n",
            "Fetched 368 kB in 0s (4,004 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cpio.\n",
            "(Reading database ... 161360 files and directories currently installed.)\n",
            "Preparing to unpack .../cpio_2.12+dfsg-6ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking cpio (2.12+dfsg-6ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.5.2-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.5.2-1ubuntu1.1) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.5.2-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking pciutils (1:3.5.2-1ubuntu1.1) ...\n",
            "Setting up cpio (2.12+dfsg-6ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /bin/mt-gnu to provide /bin/mt (mt) in auto mode\n",
            "Setting up libpci3:amd64 (1:3.5.2-1ubuntu1.1) ...\n",
            "Setting up pciutils (1:3.5.2-1ubuntu1.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "W: Operation was interrupted before it could finish\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n",
            "--2021-03-15 06:31:27--  http://registrationcenter-download.intel.com/akdlm/irc_nas/16345/l_openvino_toolkit_p_2020.1.023.tgz\n",
            "Resolving registrationcenter-download.intel.com (registrationcenter-download.intel.com)... 88.221.161.178, 88.221.161.161\n",
            "Connecting to registrationcenter-download.intel.com (registrationcenter-download.intel.com)|88.221.161.178|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 508213676 (485M) [application/octet-stream]\n",
            "Saving to: ‘l_openvino_toolkit_p_2020.1.023.tgz’\n",
            "\n",
            "l_openvino_toolkit_ 100%[===================>] 484.67M   320MB/s    in 1.5s    \n",
            "\n",
            "2021-03-15 06:31:29 (320 MB/s) - ‘l_openvino_toolkit_p_2020.1.023.tgz’ saved [508213676/508213676]\n",
            "\n",
            "CPU times: user 76.9 ms, sys: 96 ms, total: 173 ms\n",
            "Wall time: 13.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNFUanul7s1g"
      },
      "source": [
        "%%capture\n",
        "%cd l_openvino_toolkit_p_2020.1.023/\n",
        "!./install_openvino_dependencies.sh && \\\n",
        "    sed -i 's/decline/accept/g' silent.cfg && \\\n",
        "    ./install.sh --silent silent.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2enKxK_qakX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c841d5d5-fc12-46a9-bf5d-ca7e82e721ae"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EULA.txt\tinstall_openvino_dependencies.sh  pset\t\t  rpm\n",
            "install_GUI.sh\tinstall.sh\t\t\t  PUBLIC_KEY.PUB  silent.cfg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-jbjiw-7nAv"
      },
      "source": [
        "[Optional] Open Vino install check, generally not needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NJp28Oj7Ts9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30e0c36-5994-48b3-a4cd-d755114ea454"
      },
      "source": [
        "!source /opt/intel/openvino/bin/setupvars.sh && \\\n",
        "    /opt/intel/openvino/deployment_tools/demo/demo_squeezenet_download_convert_run.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[setupvars.sh] OpenVINO environment initialized\n",
            "target_precision = FP16\n",
            "[setupvars.sh] OpenVINO environment initialized\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "\n",
            "\n",
            "Downloading the Caffe model and the prototxt\n",
            "Installing dependencies\n",
            "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "48 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Run sudo -E apt -y install build-essential python3-pip virtualenv cmake libcairo2-dev libpango1.0-dev libglib2.0-dev libgtk2.0-dev libswscale-dev libavcodec-dev libavformat-dev libgstreamer1.0-0 gstreamer1.0-plugins-base\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.1).\n",
            "gstreamer1.0-plugins-base is already the newest version (1.14.5-0ubuntu1~18.04.1).\n",
            "libgstreamer1.0-0 is already the newest version (1.14.5-0ubuntu1~18.04.1).\n",
            "libavcodec-dev is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "libavcodec-dev set to manually installed.\n",
            "libavformat-dev is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "libavformat-dev set to manually installed.\n",
            "libswscale-dev is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "libswscale-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  autoconf automake autopoint autotools-dev debhelper dh-autoreconf\n",
            "  dh-strip-nondeterminism file gettext gettext-base gir1.2-atk-1.0\n",
            "  gir1.2-freedesktop gir1.2-gdkpixbuf-2.0 gir1.2-gtk-2.0 gir1.2-pango-1.0\n",
            "  intltool-debian libarchive-cpio-perl libarchive-zip-perl libatk1.0-dev\n",
            "  libcairo-script-interpreter2 libfile-stripnondeterminism-perl libgail-common\n",
            "  libgail18 libgdk-pixbuf2.0-dev libglib2.0-0 libglib2.0-bin\n",
            "  libglib2.0-dev-bin libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libmagic-mgc\n",
            "  libmagic1 libmail-sendmail-perl libpangoxft-1.0-0 libpixman-1-dev\n",
            "  libsigsegv2 libsys-hostname-long-perl libtimedate-perl libtool\n",
            "  libxcb-shm0-dev libxcomposite-dev libxcursor-dev libxinerama-dev\n",
            "  libxml2-utils libxrandr-dev m4 po-debconf python-pip-whl python3-asn1crypto\n",
            "  python3-cffi-backend python3-crypto python3-cryptography python3-idna\n",
            "  python3-keyring python3-keyrings.alt python3-pkg-resources\n",
            "  python3-secretstorage python3-setuptools python3-six python3-virtualenv\n",
            "  python3-wheel python3-xdg x11proto-composite-dev x11proto-randr-dev\n",
            "  x11proto-xinerama-dev\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc dh-make dwz gettext-doc\n",
            "  libasprintf-dev libgettextpo-dev libcairo2-doc libglib2.0-doc gvfs\n",
            "  libgtk2.0-doc imagemagick libpango1.0-doc libtool-doc gcj-jdk m4-doc\n",
            "  libmail-box-perl python-crypto-doc python-cryptography-doc\n",
            "  python3-cryptography-vectors gnome-keyring libkf5wallet-bin\n",
            "  gir1.2-gnomekeyring-1.0 python-secretstorage-doc python-setuptools-doc\n",
            "Recommended packages:\n",
            "  xdg-user-dirs\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autopoint autotools-dev debhelper dh-autoreconf\n",
            "  dh-strip-nondeterminism file gettext gettext-base gir1.2-atk-1.0\n",
            "  gir1.2-freedesktop gir1.2-gdkpixbuf-2.0 gir1.2-gtk-2.0 gir1.2-pango-1.0\n",
            "  intltool-debian libarchive-cpio-perl libarchive-zip-perl libatk1.0-dev\n",
            "  libcairo-script-interpreter2 libcairo2-dev libfile-stripnondeterminism-perl\n",
            "  libgail-common libgail18 libgdk-pixbuf2.0-dev libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libgtk2.0-dev libmagic-mgc libmagic1 libmail-sendmail-perl\n",
            "  libpango1.0-dev libpangoxft-1.0-0 libpixman-1-dev libsigsegv2\n",
            "  libsys-hostname-long-perl libtimedate-perl libtool libxcb-shm0-dev\n",
            "  libxcomposite-dev libxcursor-dev libxinerama-dev libxml2-utils libxrandr-dev\n",
            "  m4 po-debconf python-pip-whl python3-asn1crypto python3-cffi-backend\n",
            "  python3-crypto python3-cryptography python3-idna python3-keyring\n",
            "  python3-keyrings.alt python3-pip python3-pkg-resources python3-secretstorage\n",
            "  python3-setuptools python3-six python3-virtualenv python3-wheel python3-xdg\n",
            "  virtualenv x11proto-composite-dev x11proto-randr-dev x11proto-xinerama-dev\n",
            "The following packages will be upgraded:\n",
            "  libglib2.0-0 libglib2.0-bin libglib2.0-dev libglib2.0-dev-bin\n",
            "4 upgraded, 67 newly installed, 0 to remove and 44 not upgraded.\n",
            "Need to get 16.8 MB of archives.\n",
            "After this operation, 66.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-dev amd64 2.56.4-0ubuntu0.18.04.7 [1,386 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-dev-bin amd64 2.56.4-0ubuntu0.18.04.7 [102 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-bin amd64 2.56.4-0ubuntu0.18.04.7 [68.8 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-0 amd64 2.56.4-0ubuntu0.18.04.7 [1,172 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext-base amd64 0.19.8.1-6ubuntu0.3 [113 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 autopoint all 0.19.8.1-6ubuntu0.3 [426 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtool all 2.4.6-2 [194 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-autoreconf all 17 [15.8 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libarchive-zip-perl all 1.60-1ubuntu0.1 [84.6 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfile-stripnondeterminism-perl all 0.040-1.1~build1 [13.8 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-strip-nondeterminism all 0.040-1.1~build1 [5,208 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext amd64 0.19.8.1-6ubuntu0.3 [1,293 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 intltool-debian all 0.35.0+20060710.4 [24.9 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 po-debconf all 1.0.20 [232 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 debhelper all 11.1.6ubuntu2 [902 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-atk-1.0 amd64 2.28.1-1 [17.8 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-freedesktop amd64 1.56.1-1 [9,080 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-gdkpixbuf-2.0 amd64 2.36.11-2 [7,748 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoxft-1.0-0 amd64 1.40.14-1ubuntu0.1 [15.0 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gir1.2-pango-1.0 amd64 1.40.14-1ubuntu0.1 [21.6 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-gtk-2.0 amd64 2.24.32-1ubuntu1 [172 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 libarchive-cpio-perl all 0.10-1 [9,644 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk1.0-dev amd64 2.28.1-1 [79.9 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo-script-interpreter2 amd64 1.15.10-2ubuntu0.1 [53.5 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-dev amd64 0.34.0-2 [244 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0-dev amd64 1.13-2~ubuntu18.04 [6,684 B]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2-dev amd64 1.15.10-2ubuntu0.1 [626 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-dev amd64 2.36.11-2 [46.8 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango1.0-dev amd64 1.40.14-1ubuntu0.1 [288 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xinerama-dev all 2018.4-4 [2,628 B]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama-dev amd64 2:1.1.3-1 [8,404 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-randr-dev all 2018.4-4 [2,620 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr-dev amd64 2:1.5.1-1 [24.0 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor-dev amd64 1:1.1.15-1 [26.5 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-composite-dev all 1:2018.4-4 [2,620 B]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcomposite-dev amd64 1:0.4.4-2 [9,136 B]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxml2-utils amd64 2.9.4+dfsg1-6.1ubuntu1.3 [35.9 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-dev amd64 2.24.32-1ubuntu1 [2,652 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsys-hostname-long-perl all 1.5-1 [11.7 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmail-sendmail-perl all 0.80-1 [22.6 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.4 [1,653 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.4 [114 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-virtualenv all 15.1.0+ds-1.1 [43.4 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu bionic/universe amd64 virtualenv all 15.1.0+ds-1.1 [4,476 B]\n",
            "Fetched 16.8 MB in 0s (46.6 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 162373 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Preparing to unpack .../03-libglib2.0-dev_2.56.4-0ubuntu0.18.04.7_amd64.deb ...\n",
            "Unpacking libglib2.0-dev:amd64 (2.56.4-0ubuntu0.18.04.7) over (2.56.4-0ubuntu0.18.04.6) ...\n",
            "Preparing to unpack .../04-libglib2.0-dev-bin_2.56.4-0ubuntu0.18.04.7_amd64.deb ...\n",
            "Unpacking libglib2.0-dev-bin (2.56.4-0ubuntu0.18.04.7) over (2.56.4-0ubuntu0.18.04.6) ...\n",
            "Preparing to unpack .../05-libglib2.0-bin_2.56.4-0ubuntu0.18.04.7_amd64.deb ...\n",
            "Unpacking libglib2.0-bin (2.56.4-0ubuntu0.18.04.7) over (2.56.4-0ubuntu0.18.04.6) ...\n",
            "Preparing to unpack .../06-libglib2.0-0_2.56.4-0ubuntu0.18.04.7_amd64.deb ...\n",
            "Unpacking libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.7) over (2.56.4-0ubuntu0.18.04.6) ...\n",
            "Selecting previously unselected package gettext-base.\n",
            "Preparing to unpack .../07-gettext-base_0.19.8.1-6ubuntu0.3_amd64.deb ...\n",
            "Unpacking gettext-base (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "Preparing to unpack .../08-libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../09-m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../10-autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../11-autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../12-automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Selecting previously unselected package autopoint.\n",
            "Preparing to unpack .../13-autopoint_0.19.8.1-6ubuntu0.3_all.deb ...\n",
            "Unpacking autopoint (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package libtool.\n",
            "Preparing to unpack .../14-libtool_2.4.6-2_all.deb ...\n",
            "Unpacking libtool (2.4.6-2) ...\n",
            "Selecting previously unselected package dh-autoreconf.\n",
            "Preparing to unpack .../15-dh-autoreconf_17_all.deb ...\n",
            "Unpacking dh-autoreconf (17) ...\n",
            "Selecting previously unselected package libarchive-zip-perl.\n",
            "Preparing to unpack .../16-libarchive-zip-perl_1.60-1ubuntu0.1_all.deb ...\n",
            "Unpacking libarchive-zip-perl (1.60-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libfile-stripnondeterminism-perl.\n",
            "Preparing to unpack .../17-libfile-stripnondeterminism-perl_0.040-1.1~build1_all.deb ...\n",
            "Unpacking libfile-stripnondeterminism-perl (0.040-1.1~build1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../18-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package dh-strip-nondeterminism.\n",
            "Preparing to unpack .../19-dh-strip-nondeterminism_0.040-1.1~build1_all.deb ...\n",
            "Unpacking dh-strip-nondeterminism (0.040-1.1~build1) ...\n",
            "Selecting previously unselected package gettext.\n",
            "Preparing to unpack .../20-gettext_0.19.8.1-6ubuntu0.3_amd64.deb ...\n",
            "Unpacking gettext (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package intltool-debian.\n",
            "Preparing to unpack .../21-intltool-debian_0.35.0+20060710.4_all.deb ...\n",
            "Unpacking intltool-debian (0.35.0+20060710.4) ...\n",
            "Selecting previously unselected package po-debconf.\n",
            "Preparing to unpack .../22-po-debconf_1.0.20_all.deb ...\n",
            "Unpacking po-debconf (1.0.20) ...\n",
            "Selecting previously unselected package debhelper.\n",
            "Preparing to unpack .../23-debhelper_11.1.6ubuntu2_all.deb ...\n",
            "Unpacking debhelper (11.1.6ubuntu2) ...\n",
            "Selecting previously unselected package gir1.2-atk-1.0:amd64.\n",
            "Preparing to unpack .../24-gir1.2-atk-1.0_2.28.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-atk-1.0:amd64 (2.28.1-1) ...\n",
            "Selecting previously unselected package gir1.2-freedesktop:amd64.\n",
            "Preparing to unpack .../25-gir1.2-freedesktop_1.56.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-freedesktop:amd64 (1.56.1-1) ...\n",
            "Selecting previously unselected package gir1.2-gdkpixbuf-2.0:amd64.\n",
            "Preparing to unpack .../26-gir1.2-gdkpixbuf-2.0_2.36.11-2_amd64.deb ...\n",
            "Unpacking gir1.2-gdkpixbuf-2.0:amd64 (2.36.11-2) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../27-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libpangoxft-1.0-0:amd64.\n",
            "Preparing to unpack .../28-libpangoxft-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangoxft-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package gir1.2-pango-1.0:amd64.\n",
            "Preparing to unpack .../29-gir1.2-pango-1.0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking gir1.2-pango-1.0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../30-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package gir1.2-gtk-2.0.\n",
            "Preparing to unpack .../31-gir1.2-gtk-2.0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking gir1.2-gtk-2.0 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libarchive-cpio-perl.\n",
            "Preparing to unpack .../32-libarchive-cpio-perl_0.10-1_all.deb ...\n",
            "Unpacking libarchive-cpio-perl (0.10-1) ...\n",
            "Selecting previously unselected package libatk1.0-dev:amd64.\n",
            "Preparing to unpack .../33-libatk1.0-dev_2.28.1-1_amd64.deb ...\n",
            "Unpacking libatk1.0-dev:amd64 (2.28.1-1) ...\n",
            "Selecting previously unselected package libcairo-script-interpreter2:amd64.\n",
            "Preparing to unpack .../34-libcairo-script-interpreter2_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../35-libpixman-1-dev_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-shm0-dev:amd64.\n",
            "Preparing to unpack .../36-libxcb-shm0-dev_1.13-2~ubuntu18.04_amd64.deb ...\n",
            "Unpacking libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Selecting previously unselected package libcairo2-dev:amd64.\n",
            "Preparing to unpack .../37-libcairo2-dev_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../38-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../39-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-dev.\n",
            "Preparing to unpack .../40-libgdk-pixbuf2.0-dev_2.36.11-2_amd64.deb ...\n",
            "Unpacking libgdk-pixbuf2.0-dev (2.36.11-2) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../41-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libpango1.0-dev.\n",
            "Preparing to unpack .../42-libpango1.0-dev_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpango1.0-dev (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package x11proto-xinerama-dev.\n",
            "Preparing to unpack .../43-x11proto-xinerama-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-xinerama-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxinerama-dev:amd64.\n",
            "Preparing to unpack .../44-libxinerama-dev_2%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Selecting previously unselected package x11proto-randr-dev.\n",
            "Preparing to unpack .../45-x11proto-randr-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-randr-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxrandr-dev:amd64.\n",
            "Preparing to unpack .../46-libxrandr-dev_2%3a1.5.1-1_amd64.deb ...\n",
            "Unpacking libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
            "Selecting previously unselected package libxcursor-dev:amd64.\n",
            "Preparing to unpack .../47-libxcursor-dev_1%3a1.1.15-1_amd64.deb ...\n",
            "Unpacking libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Selecting previously unselected package x11proto-composite-dev.\n",
            "Preparing to unpack .../48-x11proto-composite-dev_1%3a2018.4-4_all.deb ...\n",
            "Unpacking x11proto-composite-dev (1:2018.4-4) ...\n",
            "Selecting previously unselected package libxcomposite-dev:amd64.\n",
            "Preparing to unpack .../49-libxcomposite-dev_1%3a0.4.4-2_amd64.deb ...\n",
            "Unpacking libxcomposite-dev:amd64 (1:0.4.4-2) ...\n",
            "Selecting previously unselected package libxml2-utils.\n",
            "Preparing to unpack .../50-libxml2-utils_2.9.4+dfsg1-6.1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libxml2-utils (2.9.4+dfsg1-6.1ubuntu1.3) ...\n",
            "Selecting previously unselected package libgtk2.0-dev.\n",
            "Preparing to unpack .../51-libgtk2.0-dev_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-dev (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libsys-hostname-long-perl.\n",
            "Preparing to unpack .../52-libsys-hostname-long-perl_1.5-1_all.deb ...\n",
            "Unpacking libsys-hostname-long-perl (1.5-1) ...\n",
            "Selecting previously unselected package libmail-sendmail-perl.\n",
            "Preparing to unpack .../53-libmail-sendmail-perl_0.80-1_all.deb ...\n",
            "Unpacking libmail-sendmail-perl (0.80-1) ...\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "Preparing to unpack .../54-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.4_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
            "Selecting previously unselected package python3-asn1crypto.\n",
            "Preparing to unpack .../55-python3-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python3-cffi-backend.\n",
            "Preparing to unpack .../56-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python3-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python3-crypto.\n",
            "Preparing to unpack .../57-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../58-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../59-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cryptography.\n",
            "Preparing to unpack .../60-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python3-secretstorage.\n",
            "Preparing to unpack .../61-python3-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python3-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python3-keyring.\n",
            "Preparing to unpack .../62-python3-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python3-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python3-keyrings.alt.\n",
            "Preparing to unpack .../63-python3-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python3-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../64-python3-pip_9.0.1-2.3~ubuntu1.18.04.4_all.deb ...\n",
            "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../65-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../66-python3-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-virtualenv.\n",
            "Preparing to unpack .../67-python3-virtualenv_15.1.0+ds-1.1_all.deb ...\n",
            "Unpacking python3-virtualenv (15.1.0+ds-1.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../68-python3-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python3-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python3-xdg.\n",
            "Preparing to unpack .../69-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n",
            "Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Selecting previously unselected package virtualenv.\n",
            "Preparing to unpack .../70-virtualenv_15.1.0+ds-1.1_all.deb ...\n",
            "Unpacking virtualenv (15.1.0+ds-1.1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
            "Setting up libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Setting up gir1.2-atk-1.0:amd64 (2.28.1-1) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up libarchive-zip-perl (1.60-1ubuntu0.1) ...\n",
            "Setting up python3-cffi-backend (1.11.5-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up gir1.2-freedesktop:amd64 (1.56.1-1) ...\n",
            "Setting up libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.7) ...\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "Setting up python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up libpangoxft-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libxml2-utils (2.9.4+dfsg1-6.1ubuntu1.3) ...\n",
            "Setting up libarchive-cpio-perl (0.10-1) ...\n",
            "Setting up gir1.2-gdkpixbuf-2.0:amd64 (2.36.11-2) ...\n",
            "Setting up gettext-base (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up python3-wheel (0.30.0-0.2) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up gir1.2-pango-1.0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up python3-asn1crypto (0.24.0-1) ...\n",
            "Setting up libsys-hostname-long-perl (1.5-1) ...\n",
            "Setting up libmail-sendmail-perl (0.80-1) ...\n",
            "Setting up x11proto-xinerama-dev (2018.4-4) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Setting up x11proto-randr-dev (2018.4-4) ...\n",
            "Setting up libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Setting up python3-virtualenv (15.1.0+ds-1.1) ...\n",
            "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
            "Setting up python3-setuptools (39.0.1-2) ...\n",
            "Setting up libglib2.0-bin (2.56.4-0ubuntu0.18.04.7) ...\n",
            "Setting up virtualenv (15.1.0+ds-1.1) ...\n",
            "Setting up x11proto-composite-dev (1:2018.4-4) ...\n",
            "Setting up autopoint (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up libfile-stripnondeterminism-perl (0.040-1.1~build1) ...\n",
            "Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
            "Setting up libglib2.0-dev-bin (2.56.4-0ubuntu0.18.04.7) ...\n",
            "Setting up gettext (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up libxcomposite-dev:amd64 (1:0.4.4-2) ...\n",
            "Setting up python3-keyrings.alt (3.0-1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libglib2.0-dev:amd64 (2.56.4-0ubuntu0.18.04.7) ...\n",
            "Setting up intltool-debian (0.35.0+20060710.4) ...\n",
            "Setting up libgdk-pixbuf2.0-dev (2.36.11-2) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Setting up python3-secretstorage (2.3.1-2) ...\n",
            "Setting up gir1.2-gtk-2.0 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libtool (2.4.6-2) ...\n",
            "Setting up po-debconf (1.0.20) ...\n",
            "Setting up libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up python3-keyring (10.6.0-1) ...\n",
            "Setting up libatk1.0-dev:amd64 (2.28.1-1) ...\n",
            "Setting up libpango1.0-dev (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libgtk2.0-dev (2.24.32-1ubuntu1) ...\n",
            "Setting up dh-autoreconf (17) ...\n",
            "Setting up debhelper (11.1.6ubuntu2) ...\n",
            "Setting up dh-strip-nondeterminism (0.040-1.1~build1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libpng-dev is already the newest version (1.6.34-1ubuntu0.18.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 1)) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 2)) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 2)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 2)) (2.10)\n",
            "Run python3 /opt/intel/openvino_2020.1.023/deployment_tools/open_model_zoo/tools/downloader/downloader.py --name squeezenet1.1 --output_dir /root/openvino_models/models --cache_dir /root/openvino_models/cache\n",
            "\n",
            "################|| Downloading models ||################\n",
            "\n",
            "========== Downloading /root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.prototxt\n",
            "... 100%, 9 KB, 51788 KB/s, 0 seconds passed\n",
            "\n",
            "========== Downloading /root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.caffemodel\n",
            "... 100%, 4834 KB, 24519 KB/s, 0 seconds passed\n",
            "\n",
            "################|| Post-processing ||################\n",
            "\n",
            "========== Replacing text in /root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.prototxt\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "Install Model Optimizer dependencies\n",
            "\n",
            "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "44 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-pip is already the newest version (9.0.1-2.3~ubuntu1.18.04.4).\n",
            "The following additional packages will be installed:\n",
            "  gcc-6-base python3.6-venv\n",
            "The following NEW packages will be installed:\n",
            "  gcc-6-base libgfortran3 python3-venv python3.6-venv\n",
            "0 upgraded, 4 newly installed, 0 to remove and 44 not upgraded.\n",
            "Need to get 294 kB of archives.\n",
            "After this operation, 1,438 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gcc-6-base amd64 6.5.0-2ubuntu1~18.04 [16.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libgfortran3 amd64 6.5.0-2ubuntu1~18.04 [270 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3.6-venv amd64 3.6.9-1~18.04ubuntu1.4 [6,188 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-venv amd64 3.6.7-1~18.04 [1,208 B]\n",
            "Fetched 294 kB in 0s (3,464 kB/s)\n",
            "Selecting previously unselected package gcc-6-base:amd64.\n",
            "(Reading database ... 165114 files and directories currently installed.)\n",
            "Preparing to unpack .../gcc-6-base_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking gcc-6-base:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package libgfortran3:amd64.\n",
            "Preparing to unpack .../libgfortran3_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking libgfortran3:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package python3.6-venv.\n",
            "Preparing to unpack .../python3.6-venv_3.6.9-1~18.04ubuntu1.4_amd64.deb ...\n",
            "Unpacking python3.6-venv (3.6.9-1~18.04ubuntu1.4) ...\n",
            "Selecting previously unselected package python3-venv.\n",
            "Preparing to unpack .../python3-venv_3.6.7-1~18.04_amd64.deb ...\n",
            "Unpacking python3-venv (3.6.7-1~18.04) ...\n",
            "Setting up gcc-6-base:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Setting up python3.6-venv (3.6.9-1~18.04ubuntu1.4) ...\n",
            "Setting up python3-venv (3.6.7-1~18.04) ...\n",
            "Setting up libgfortran3:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.7/dist-packages (from -r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 1)) (2.5)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from -r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 2)) (1.17.5)\n",
            "Collecting protobuf==3.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/30/289ead101f94998d88e8961a3548aea29417ae0057be23972483cddebf4f/protobuf-3.6.1-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: defusedxml>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=1.11->-r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf==3.6.1->-r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf==3.6.1->-r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 3)) (54.0.0)\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.17.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement protobuf>=3.9.2, but you'll have protobuf 3.6.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-metadata 0.28.0 has requirement protobuf<4,>=3.7, but you'll have protobuf 3.6.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-hub 0.11.0 has requirement protobuf>=3.8.0, but you'll have protobuf 3.6.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: googleapis-common-protos 1.53.0 has requirement protobuf>=3.12.0, but you'll have protobuf 3.6.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-core 1.26.1 has requirement protobuf>=3.12.0, but you'll have protobuf 3.6.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: protobuf\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "Successfully installed protobuf-3.6.1\n",
            "[WARNING] All Model Optimizer dependencies are installed globally.\n",
            "[WARNING] If you want to keep Model Optimizer in separate sandbox\n",
            "[WARNING] run install_prerequisites.sh venv {caffe|tf|mxnet|kaldi|onnx}\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "Convert a model with Model Optimizer\n",
            "\n",
            "Run python3 /opt/intel/openvino_2020.1.023/deployment_tools/open_model_zoo/tools/downloader/converter.py --mo /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/mo.py --name squeezenet1.1 -d /root/openvino_models/models -o /root/openvino_models/ir --precisions FP16\n",
            "\n",
            "========= Converting squeezenet1.1 to IR (FP16)\n",
            "Conversion command: /usr/bin/python3 -- /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/mo.py --framework=caffe --data_type=FP16 --output_dir=/root/openvino_models/ir/public/squeezenet1.1/FP16 --model_name=squeezenet1.1 '--input_shape=[1,3,227,227]' --input=data '--mean_values=data[104.0,117.0,123.0]' --output=prob --input_model=/root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.caffemodel --input_proto=/root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.prototxt\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \t/root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.caffemodel\n",
            "\t- Path for generated IR: \t/root/openvino_models/ir/public/squeezenet1.1/FP16\n",
            "\t- IR output name: \tsqueezenet1.1\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \tNot specified, inherited from the model\n",
            "\t- Input layers: \tdata\n",
            "\t- Output layers: \tprob\n",
            "\t- Input shapes: \t[1,3,227,227]\n",
            "\t- Mean values: \tdata[104.0,117.0,123.0]\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tFalse\n",
            "\t- Reverse input channels: \tFalse\n",
            "Caffe specific parameters:\n",
            "\t- Path to Python Caffe* parser generated from caffe.proto: \t/opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/mo/front/caffe/proto\n",
            "\t- Enable resnet optimization: \tTrue\n",
            "\t- Path to the Input prototxt: \t/root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.prototxt\n",
            "\t- Path to CustomLayersMapping.xml: \tDefault\n",
            "\t- Path to a mean file: \tNot specified\n",
            "\t- Offsets for a mean file: \tNot specified\n",
            "Model Optimizer version: \t2020.1.0-61-gd349c3ba4a\n",
            "\n",
            "[ SUCCESS ] Generated IR version 10 model.\n",
            "[ SUCCESS ] XML file: /root/openvino_models/ir/public/squeezenet1.1/FP16/squeezenet1.1.xml\n",
            "[ SUCCESS ] BIN file: /root/openvino_models/ir/public/squeezenet1.1/FP16/squeezenet1.1.bin\n",
            "[ SUCCESS ] Total execution time: 4.37 seconds. \n",
            "[ SUCCESS ] Memory consumed: 114 MB. \n",
            "\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "Build Inference Engine samples\n",
            "\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Looking for C++ include unistd.h\n",
            "-- Looking for C++ include unistd.h - found\n",
            "-- Looking for C++ include stdint.h\n",
            "-- Looking for C++ include stdint.h - found\n",
            "-- Looking for C++ include sys/types.h\n",
            "-- Looking for C++ include sys/types.h - found\n",
            "-- Looking for C++ include fnmatch.h\n",
            "-- Looking for C++ include fnmatch.h - found\n",
            "-- Looking for strtoll\n",
            "-- Looking for strtoll - found\n",
            "-- Found InferenceEngine: /opt/intel/openvino_2020.1.023/deployment_tools/inference_engine/lib/intel64/libinference_engine.so (Required is at least version \"2.1\") \n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /root/inference_engine_samples_build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target gflags_nothreads_static\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target format_reader\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object thirdparty/gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object thirdparty/gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object thirdparty/gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/MnistUbyte.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/format_reader.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/bmp.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/opencv_wraper.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32m\u001b[1mLinking CXX static library ../../intel64/Release/lib/libgflags_nothreads.a\u001b[0m\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX shared library ../../intel64/Release/lib/libformat_reader.so\u001b[0m\n",
            "[ 81%] Built target gflags_nothreads_static\n",
            "[ 81%] Built target format_reader\n",
            "\u001b[35m\u001b[1mScanning dependencies of target classification_sample_async\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object classification_sample_async/CMakeFiles/classification_sample_async.dir/main.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/classification_sample_async\u001b[0m\n",
            "[100%] Built target classification_sample_async\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "Run Inference Engine classification sample\n",
            "\n",
            "Run ./classification_sample_async -d CPU -i /opt/intel/openvino/deployment_tools/demo/car.png -m /root/openvino_models/ir/public/squeezenet1.1/FP16/squeezenet1.1.xml\n",
            "\n",
            "[ INFO ] InferenceEngine: \n",
            "\tAPI version ............ 2.1\n",
            "\tBuild .................. 37988\n",
            "\tDescription ....... API\n",
            "[ INFO ] Parsing input parameters\n",
            "[ INFO ] Parsing input parameters\n",
            "[ INFO ] Files were added: 1\n",
            "[ INFO ]     /opt/intel/openvino/deployment_tools/demo/car.png\n",
            "[ INFO ] Creating Inference Engine\n",
            "\tCPU\n",
            "\tMKLDNNPlugin version ......... 2.1\n",
            "\tBuild ........... 37988\n",
            "\n",
            "[ INFO ] Loading network files\n",
            "[ INFO ] Preparing input blobs\n",
            "[ WARNING ] Image is resized from (787, 259) to (227, 227)\n",
            "[ INFO ] Batch size is 1\n",
            "[ INFO ] Loading model to the device\n",
            "[ INFO ] Create infer request\n",
            "[ INFO ] Start inference (10 asynchronous executions)\n",
            "[ INFO ] Completed 1 async request execution\n",
            "[ INFO ] Completed 2 async request execution\n",
            "[ INFO ] Completed 3 async request execution\n",
            "[ INFO ] Completed 4 async request execution\n",
            "[ INFO ] Completed 5 async request execution\n",
            "[ INFO ] Completed 6 async request execution\n",
            "[ INFO ] Completed 7 async request execution\n",
            "[ INFO ] Completed 8 async request execution\n",
            "[ INFO ] Completed 9 async request execution\n",
            "[ INFO ] Completed 10 async request execution\n",
            "[ INFO ] Processing output blobs\n",
            "\n",
            "Top 10 results:\n",
            "\n",
            "Image /opt/intel/openvino/deployment_tools/demo/car.png\n",
            "\n",
            "classid probability label\n",
            "------- ----------- -----\n",
            "817     0.6853039   sports car, sport car\n",
            "479     0.1835192   car wheel\n",
            "511     0.0917195   convertible\n",
            "436     0.0200692   beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\n",
            "751     0.0069603   racer, race car, racing car\n",
            "656     0.0044177   minivan\n",
            "717     0.0024739   pickup, pickup truck\n",
            "581     0.0017788   grille, radiator grille\n",
            "468     0.0013083   cab, hack, taxi, taxicab\n",
            "661     0.0007443   Model T\n",
            "\n",
            "[ INFO ] Execution successful\n",
            "\n",
            "[ INFO ] This sample is an API example, for any performance measurements please use the dedicated benchmark_app tool\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "Demo completed successfully.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TygLw4WIO8BD"
      },
      "source": [
        "### Here we run some modifications in the ssd2 OpenVINO extension for TF so that our Mobilenet SSDv2 model can convert successfully to the IR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-bGZHGcMNbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea3547a-297e-432c-8bb6-181c11195b40"
      },
      "source": [
        "%cd /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/\n",
        "#openvino fixes: edit \n",
        "# Read in the file, make sure the .json corresponds to the model!!!\n",
        "with open('ssd_v2_support.json', 'r') as file :\n",
        "  filedata = file.read()\n",
        "\n",
        "# Replace the target string\n",
        "filedata = filedata.replace('\"Postprocessor/ToFloat\"', '\"Postprocessor/Cast_1\"')\n",
        "\n",
        "# Write the file out again\n",
        "with open('ssd_v2_support.json', 'w') as file:\n",
        "  file.write(filedata)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/extensions/front/tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROig0wlCkxoX"
      },
      "source": [
        "%cp \"/content/models/research/fine_tuned_model/saved_model/saved_model.pb\" \"/content/models/research/fine_tuned_model/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7sqTX79W6hh"
      },
      "source": [
        "## Convert TF model to Open Vino Intermediate Representation\n",
        "If using own model, please change to your desired name for output directory --output_dir \"choose name\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsWggE5AIWS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f69b4f0-8a64-4c43-cb30-f554c6ff0b3f"
      },
      "source": [
        "#CONVERT TF MODEL to OPEN VINO IRv10. saved in IR_V10_fruits_mnssdv2_6k directory or\n",
        "#choose own name for --output_dir \"choose name\"\n",
        "%cd \"/content/models/research/fine_tuned_model/\"\n",
        "!source /opt/intel/openvino/bin/setupvars.sh && \\\n",
        "    python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n",
        "    --input_model frozen_inference_graph.pb \\\n",
        "    --tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json \\\n",
        "    --tensorflow_object_detection_api_pipeline_config pipeline.config \\\n",
        "    --reverse_input_channels \\\n",
        "    --output_dir signs \\\n",
        "    --data_type FP16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/fine_tuned_model\n",
            "[setupvars.sh] OpenVINO environment initialized\n",
            "[ WARNING ]  Use of deprecated cli option --tensorflow_use_custom_operations_config detected. Option use in the following releases will be fatal. Please use --transformations_config cli option instead\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \t/content/models/research/fine_tuned_model/frozen_inference_graph.pb\n",
            "\t- Path for generated IR: \t/content/models/research/fine_tuned_model/signs\n",
            "\t- IR output name: \tfrozen_inference_graph\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \tNot specified, inherited from the model\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \tNot specified, inherited from the model\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tFalse\n",
            "\t- Reverse input channels: \tTrue\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tFalse\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \t/content/models/research/fine_tuned_model/pipeline.config\n",
            "\t- Operations to offload: \tNone\n",
            "\t- Patterns to offload: \tNone\n",
            "\t- Use the config file: \t/opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json\n",
            "Model Optimizer version: \t2020.1.0-61-gd349c3ba4a\n",
            "The Preprocessor block has been removed. Only nodes performing mean value subtraction and scaling (if applicable) are kept.\n",
            "\n",
            "[ SUCCESS ] Generated IR version 10 model.\n",
            "[ SUCCESS ] XML file: /content/models/research/fine_tuned_model/signs/frozen_inference_graph.xml\n",
            "[ SUCCESS ] BIN file: /content/models/research/fine_tuned_model/signs/frozen_inference_graph.bin\n",
            "[ SUCCESS ] Total execution time: 33.91 seconds. \n",
            "[ SUCCESS ] Memory consumed: 1719 MB. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9R7LTkNvZos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5020a86-5d89-4c41-b230-1219f8c42618"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P15Hl-Fbmkib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18acde30-843f-45bf-a33a-fe8f107cf00a"
      },
      "source": [
        "#check directory containing the exported TF trained model and the IRv10 folder\n",
        "%ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint                      model.ckpt.index  \u001b[0m\u001b[01;34msaved_model\u001b[0m/\n",
            "frozen_inference_graph.pb       model.ckpt.meta   saved_model.pb\n",
            "model.ckpt.data-00000-of-00001  pipeline.config   \u001b[01;34msigns\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD2BMtXoPjYN"
      },
      "source": [
        "## Now we compile the IR model to a .blob for use on DepthAI modules/platform\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqZqajTIP3Sv"
      },
      "source": [
        "### We save the blob in the IR directory from above, corresponding to --output_dir parameter above. \n",
        "The blob filename will be *frozen_inference_graph.blob*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBDt-QKvlcdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e239b2-ca82-4557-aa70-2375a49581a3"
      },
      "source": [
        "%ls /content/models/research/fine_tuned_model/signs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frozen_inference_graph.bin      frozen_inference_graph.xml\n",
            "frozen_inference_graph.mapping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqiPpnCwPioH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baab7701-29ee-433c-d25c-7c34b8a6da83"
      },
      "source": [
        "#No changes needed here unless using custom data.\n",
        "#CHOOSE the directory where you would like to save the blob.\n",
        "# I use the same --output_dir as above for the IR conversion\n",
        "blob_dir = \"/content/models/research/fine_tuned_model/signs/\"\n",
        "\n",
        "#Copy the path of your .xml and .bin files. For that, you can look at the IR\n",
        "#conversion output cell, select and copy from:\n",
        "#[SUCCESS] XML file and bin file paths.\n",
        "#Or you can choose to compile other .xml .bin files from a different location\n",
        "#\n",
        "xmlfile = \"/content/models/research/fine_tuned_model/signs/frozen_inference_graph.xml\"\n",
        "binfile = \"/content/models/research/fine_tuned_model/signs/frozen_inference_graph.bin\"\n",
        "\n",
        "import requests\n",
        "\n",
        "#For openvino 20.01 use this link to compile the blob\n",
        "url = \"http://69.164.214.171:8080\"\n",
        "\n",
        "\n",
        "#open vino 20.02 link:\n",
        "# url = \"69.164.214.171:8081\"\n",
        "\n",
        "payload = {'compiler_params': '-ip U8 -VPU_MYRIAD_PLATFORM VPU_MYRIAD_2480 -VPU_NUMBER_OF_SHAVES 4 -VPU_NUMBER_OF_CMX_SLICES 4'}\n",
        "files = [\n",
        "  ('definition', open(xmlfile,'rb')),\n",
        "  ('weights', open(binfile,'rb'))\n",
        "]\n",
        "# headers = {\n",
        "#   'Content-Type': 'application/json'\n",
        "# }\n",
        "response = requests.request(\"POST\", url, data = payload, files = files)\n",
        "blobnameraw = response.headers.get('Content-Disposition')\n",
        "print(blobnameraw)\n",
        "blobname = blobnameraw[blobnameraw.find('='):][1:]\n",
        "with open(blob_dir + blobname, 'wb') as f:\n",
        "  f.write(response.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attachment; filename=frozen_inference_graph.blob\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qJ0knjImLIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3f9fed03-13bc-4bd2-8b4d-4812ffbfb62d"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/models/research/fine_tuned_model/signs/frozen_inference_graph.blob')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ced5d77c-af24-4783-b8ba-a85cddf6fcb8\", \"frozen_inference_graph.blob\", 14279104)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24-2kaAFvyEd"
      },
      "source": [
        "## To run the .blob in DepthAI, we proceed step 5 here:\n",
        " https://docs.luxonis.com/tutorials/object_det_mnssv2_training/"
      ]
    }
  ]
}